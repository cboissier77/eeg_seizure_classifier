seed: 42
data:
  data_dir: "./data/data/"
  train_split: 0.8
  train_subsample: 1.0
  validation_id_epoch_tuning: 's002'
  hypertuning_subjects_ids:
    - 's001'
    - 's004'
    - 's005'
    - 's007'
    - 's009'
    - 's010'
    - 's011'
  preprocessing: "normalize"


model:
  name: "transformer_encoder"
  input_dim: 1
  embed_dim: 64
  output_dim: 1
  patch_size: 10
  num_layers: 2
  nhead: 4
  
training:
  batch_size: 32
  lr: 0.00005
  epochs: 3
  best_model_path: "./results/trained_model.pth"
  max_epochs: 30
  n_trials: 5 # number of trials for hyperparameter tuning

loss:
  alpha: 0.75
  gamma: 2.0

